# XMUAssistantBot

**XMUAssistantBot** 是一款专为 **厦门大学转专业交流群** 定制的高性能自动化管理机器人。它基于 Rust 异步生态，通过自研消息路由与分层存储架构，在处理 2000 人规模高并发群聊场景下，实现了极致的 I/O 效率与低内存分配。

------

## ⚡ 性能基准 (Performance Benchmark)

基于项目内 `benches/` 模块的实测数据（环境：Windows 11 x64, Release Mode）：
**注意：基准测试环境已修复因内存布局不一致导致的崩溃风险，现在测试结果更具健壮性和可靠性。**

### 1. 消息路由与分发 (ABI Efficiency)

通过宏优化和精确的命令过滤，大幅减少了不必要的异步任务创建和路由开销。

| 场景 | 核心指标 | 最新耗时 | 性能变化 |
|---|---|---|---|
| 命令命中路由 (`routing_hit_first`) | 核心命令处理前置过滤与路由时长 | `497.94 ns` | 显著优化 |
| 命令未命中路由 (`routing_miss_all`) | 未匹配消息的过滤与退出时长 | `500.71 ns` | 显著优化 |
| 轻量化 Context 克隆 | 精简 Context 结构的复制开销 | `41.39 ns` | (维持超低) |
| 并发 Handler 分发 (x10) | 模拟 10 个 Handler 同时并行运行的系统级开销 | `20.10 µs` | (维持超低) |

### 2. 存储系统性能

采用分层存储策略，并通过定长序列化和优化并发读写来确保性能。

| 场景 | 核心指标 | 最新耗时 | 性能变化 |
|---|---|---|---|
| 冷存储读取命中 (`cold_get_hit`) | 从 Redb 冷存储中读取单个 Key 的耗时 | `12.044 µs` | 轻微退化 (+1.12%) |
| 高并发热存储吞吐 (`hottable_concurrent_read_write_x100_90_10`) | 100路并发读写 DashMap 耗时 | `51.941 µs` | 轻微退化 (+10%) |
| 冷存储写入 (`cold_insert`) | 写入 Redb 冷存储耗时 | `2.1873 ms` | 轻微优化 (-3.4%) |

### 3. 序列化与协议解析 (Stability Focus)

**注意：此部分已移除 LazyString 零拷贝机制，追求稳定性而非极限 I/O 延迟。此外，通过条件编译，在 Release 模式下会启用更快的 JSON 解析库，进一步提升性能。**

| 场景 | 核心指标 | 最新耗时 | 性能变化 |
|---|---|---|---|
| 反序列化 (`json_deserialize_message_receive`) | 消息体 JSON 反序列化耗时 | `1.2562 µs` | 结构重构 |
| 消息体序列化 (`json_serialize_message_send`) | 消息体 JSON 序列化耗时 | `372.11 ns` | 结构重构 |
| 文本段数组获取 (`get_text_array`) | 文本段数组获取耗时 | `95.196 ns` | 轻微退化 (+4%) |
| 定长文本获取 (`get_text_single`) | 优化后定长字符串获取耗时 | `26.565 ns` | 轻微退化 (+7%) |

------

## 🛠️ 深度技术优化 (Technical Deep Dive)

### 1. 消息体结构重构与性能平衡

- **移除 LazyString/ArcWith**: 出于对 LLM 性能分析的需求，以及简化代码编写和降低心智负担的考虑，项目移除了基于 `LazyString` 和 `ArcWith` 的零拷贝接收机制。消息体的解析现在直接在反序列化阶段完成，以此换取更高的结构稳定性、消除额外的心智负担和降低 LLM 上下文构建的复杂度。
- **MiMalloc 全局分配器**: 放弃系统默认分配器，采用 `MiMalloc` 优化瞬时大量 JSON 对象的分配，极大降低内存碎片率和全局锁竞争。
- **哈希性能**: 引入 `ahash::RandomState` 作为全局哈希状态，以获得更优的哈希性能和更强的抗碰撞能力。
- **栈空间优先与健壮序列化**:
  - 大量使用 `smol_str` 存储短字符串，通过 Inline 优化避免堆分配。
  - **`define_default_type!` 宏**: 确保 API 响应中的可选字段在缺失或为 `null` 时，能健壮地使用默认值。

### 2. 健壮性与零克隆优化

项目在多个关键路径上进行了微优化，以实现零克隆和高健壮性：

- **健壮性增强**: 将 `src/main.rs`, `src/config.rs` 和 `src/web/mod.rs` 中关键启动/I/O 操作的 `unwrap()` 替换为 `expect()` 或 `?`，增强了程序的健壮性并提供了更清晰的错误信息 (#17)。
- **I/O 异步化**: 将所有文件系统操作（如 `File` 模块）移动到 `tokio` 异步运行时内执行，**彻底避免了文件 I/O 阻塞主线程** (#7)。
- **非安全性能提升**: 在 `src/logic/login/process.rs` 登录流程中，使用 `unsafe { get_unchecked(...) }` 对年份字符串进行切片，**在确保数据格式正确的前提下，消除了运行时的边界检查开销** (#10)。
- **零克隆优化**:
    - **消息发送**: 移除了基于 `AnyCast` 的动态分发，改用性能更高的静态消息传递方式，并为 `Dice`/`Rps`/`Shake` 等小型消息体实现了 `Copy` trait，**消除了消息处理流程中的不必要克隆** (#5, #9)。
    - **字符串与所有权**:
        - 优化了 `send_msg.rs` 中的字符串处理，减少了克隆 (#11)。
        - 优化了 `set_cookie` 签名，避免了 URL 克隆 (#12)。
        - 优化了教务（`jw`）和学习通（`lnt`）模块中常量 URL 的处理，避免不必要的克隆 (#13)。
        - 通过在 `choose_files.rs` 中转移 `HashMap` 所有权，避免了批量文件名的克隆 (#14)。
        - 移除了 `ExposeFileTask::finish` 中对文件列表的不必要克隆 (#15)。
- **并发结构清理**: 移除了 `src/abi/echo.rs` 中不必要的 `DashSet`，提高了并发性能 (#3)。
- **配置清理**: 移除了 `src/api/storage/hot.rs` 中重复的 `BINCODE_CONFIG` 定义，保持了配置的一致性 (#16)。

### 3. 宏驱动的 LLM 工具化与类型安全

- **LLM 类型安全封装**: 引入 `LlmI64`、`LlmVec` 等自定义封装类型，强制 LLM 输出结构化数据。该机制旨在解决 LLM 返回格式不规范的问题，极大地提高了 LLM 工具调用的准确性和健壮性。
- **LlmPrompt 灵活化**: 实现了 `#[derive(LlmPrompt)]` 宏参数的解耦，允许在字段级别使用 `#[prompt("...")]` 定义描述信息，使 Prompt 的生成更加灵活和精确。
- **LlmFile 抽象**: 引入 `LlmFile` 类对文件进行抽象。该抽象使用文件内容的 **SHA-256 校验和的前八位** 作为唯一标识符 (`FileShortId`)，并结合了文件别名和持久化存储，方便 LLM 在对话中安全、准确地引用和操作文件。
- **LLM 响应格式化**: 实现了从 LLM 的原始 `ChatResponse` 到规范的 `MessageSendLlmResponse` 结构的反序列化，再到最终的 `MessageSend` 消息体转换的完整流程，确保了 LLM 生成的消息能够正确地在 OneBot 协议中发送。

### 3. 消息流与文件处理增强

- **急速路径（Repeat）回复**: 实现了基于 **用户 ID + 消息文本摘要** 的急速路径缓存机制。对于重复出现的特定消息，系统会直接返回预缓存的 `MessageSend`，无需再次进行 LLM 推理，有效提高了响应速度。
- **File 消息类型兼容**: 兼容了 `file` 类型的消息发送，并实现了基于 `FileUrl<T>` 结构的 `download` 消息体文件合并转发，确保了文件在转发过程中的生命周期管理。
- **FileUrl 增强**: 提供了从本地 `Path` 获取 `file://` 格式 `FileUrl` 的功能，支持本地文件作为消息段进行发送。

### 4. 基于过程宏的元编程 (Helper Macros)

项目高度依赖自研过程宏来自动化重复代码、确保运行时性能和安全。

- **`box_new!` 过程宏**: 新增过程宏，用于在堆上安全地构造对象。它通过**编译时字段检查**（利用解构模式匹配失败的技巧）确保所有字段都被初始化，**在提供便利性的同时，防止了因字段遗漏导致的运行时错误**，显著提升了代码的安全性和健壮性 (#2)。

- **`#[handler]` / `register_handlers!` 性能与功能增强**:
    - **发送机制固定化**: 消息的最终处理（如发送回执）逻辑已从不安全的 `Drop` 钩子转移，固定到 `#[handler]` 宏生成的异步任务末尾（`ctx.finish().await`），**确保了发送机制的统一性和可预测性** (#4)。
    - **零成本过滤**: 宏在 `handle` 方法中加入前置同步检查 (`type_filter` 和 `command_filter`)，只有当命中指令时，才调用 `tokio::spawn` 启动异步 Handler 协程。**此优化避免了为不匹配消息创建昂贵的 `tokio::spawn` 协程，显著降低了路由开销**，同时**减少了 Context 对象的克隆**。
    - **自动化 Help 文档**: `#[handler(command = "cmd", help_msg = "描述")]` 现在强制要求提供帮助信息。宏会自动实现 `BuildHelp` trait，结合 `register_handler_with_help!` 宏，**实现了编译时自动聚合所有指令的帮助信息，无需手动维护 Help 命令**。
    - **消息传递优化**: 实现了修改传递 `Uft8Bytes` 替代 `String`，以减少序列化开销。
- **OneBot v11 API 框架与宏简化**:
    - **宏简化**: `#[api]` 宏提供了更简洁的声明式语法 `#[api("/action", ResponseType)]`，自动化实现 API 参数结构体、动作名称和响应类型绑定。同时，`#[session_client_helper]` 宏进一步简化了业务逻辑层对 `SessionClient` 的调用。
    - **API 扩展**: 新增对 OneBot V11 的多个核心 API 接入，包括：**获取合并转发消息 (`get_forward_msg`)、获取群信息 (`get_group_info`)、获取群成员信息 (`group_member_info`)、戳一戳 (`send_group_poke`)**，极大地增强了机器人的群管理和消息处理能力。
    - **消息结构精简**: 严格遵守 OneBot V11 协议标准，对消息结构体进行了精简和修复，移除了协议未提及的冗余字段（如在序列化时跳过内部 `MessageReceive` 字段），确保了消息接收与发送的兼容性和健壮性。
- **新增特殊头衔 API**: 实现了 `set_group_special_title` 接口的封装，支持在群聊中设置特殊头衔。
- **核心 Client 抽象**: 核心 API Client 逻辑（如获取 `SessionClient`）已被重构，从宏中剥离出可复用的 `castgc` 和 `session` 模块，大幅减少了重复代码。`logic/helper` 模块的引入，也为一键获取 `SessionClient` 提供了便利。
- **`#[jw_api]` (教务系统)**: 智能适配教务系统非标准的 JSON 嵌套结构，**现已支持配置 `call_type = "GET"` 或 `"POST"`**，以适应教务系统复杂的接口请求方式。
- **教务系统新增路径 (JW Schedule)**: 在 `src/api/xmu_service/jw/` 下新增 `schedule` 模块，提供了包括**课表列表、时间、可读格式**等在内的多项教务系统信息获取路径。

### 5. 异步 I/O 与分层存储架构

项目实现了 **Hot-Cold-File** 语义化分层存储系统：

- **Hot 层 (DashMap)**: 存储当前活跃的会话（`LoginData`），读写复杂度 $O(1)$。
- **Cold 层 (Redb)**: 采用 Copy-on-Write (CoW) 机制的嵌入式数据库，通过异步 Task 批量提交事务，完全剥离主循环 I/O。**新增 `get_all()` 遍历方法**，支持在服务启动时加载全部数据用于重建内存索引 (#6)。
- **Hot 层和 Cold 层定长 bincode**: 存储层使用定长的 `bincode` 格式，牺牲少量空间换取更一致、更优秀的序列化/反序列化性能，有效提升 `cold_get_hit` 性能。
- **RAII 临时文件管理**: 自研 `TempFile` 系统，利用 `Drop` 钩子自动触发异步清理，确保存储空间整洁。
- **ABI & WebSocket 健壮性**: Handler 异常屏障在显示错误时会显示出错函数，在 WebSocket 生命周期结束时会自动断连。

### 6. 强大的 LLM 上下文与归档系统

- **向量搜索引擎与 RAG**: 新增了基于 `hnsw_rs` 的 `VectorSearchEngine` 模块，用于高性能的 `embedding` 向量检索 (#8)。
    - **混合存储架构**: 引擎在初始化时，从 `ColdTable` (Redb) 中加载所有数据，并在内存中构建一个 HNSW（分层可导航小世界）图索引，用于高速的近似最近邻搜索。
    - **高效检索**: 它将 CPU 密集的搜索操作放在 `tokio::spawn_blocking` 中执行，避免阻塞异步运行时。搜索返回内部 ID 后，通过内存中的 `DashMap` 映射到持久化 `Uuid`，最终从 `ColdTable` 中获取原始数据，实现了高效的 RAG（检索增强生成）。
- **Embedding 支持**: 完成了 LLM Embedding 模型的配置和集成，为后续的 RAG (检索增强生成) 和更高级的上下文匹配奠定了基础。
- **消息流自动归档**: 实现了消息和通知的自动存储（持久化），作为 LLM 聊天历史的上下文来源。同时，通过调用 OneBot API 实现了**群组和人员身份信息**的自动归档与更新。
- **消息到 ChatMessage 的高级转换**: 深度集成了 `genai` 库的 `ChatMessage` 格式。实现了复杂的 OneBot 消息段转换，包括：
    - **多模态支持**: 将图片、语音、视频、Face 表情转换为 LLM 可理解的 `Binary`（URL 或 Base64 嵌入）。
    - **上下文重建**: 自动处理 `Reply` 和 `Forward` 消息，通过归档系统获取原始消息内容，并注入到当前消息的上下文流中。
    - **结构化身份注入**: 对于 `@At` 和 `Contact` 消息，查询归档的身份信息（如昵称、群名），并以结构化 XML 格式注入到消息体中，供 LLM 精确识别和使用。

### 7. Lnt API 深度集成

- **Lnt API 深度集成**: 实现了包括 `activities`、`file_url`、`my_courses`、`profile` 修正等在内的 LNT API 封装，并**新增了考试查询、成绩与试题分发等关键接口**：`distribute` (获取试题)、`exams` (考试列表)、`submissions` (提交记录) 和 `submission_id` (查询答案)。
- **Lnt 文件缓存**: 对 Lnt API 获取的文件下载链接和文件本身进行了缓存管理 (`FILE_DATA` ColdTable)，实现了获取 URL -> 下载文件 -> 存储的完整链条，避免重复下载。

### 8. LLM 工具驱动

- **LLM 工具描述生成**: 通过 `#[derive(LlmPrompt)]` 宏，结合新的 **LLM 类型安全封装**（如 `LlmI64`, `LlmVec` 等），自动从 Rust 结构体中提取信息，生成 LLM 函数调用所需的高准确率 Schema。该机制解决了模型返回格式不精确的问题，实现了实测高准确率的工具化调用。
- **LlmFile 上下文**: 工具能够直接识别和引用由 `LlmFile` 抽象管理的文件 ID，使 LLM 能在 Tool Call 中处理文件参数。

### 9. 其他核心优化

- **编译优化**: 升级了编译优化配置，生成效率更高的二进制文件。
- **智能 JSON**: 提供了更加智能的 JSON 解析函数，在 Release 模式下等效于原本的快速 JSON 函数，同时提升了开发和报错体验。

### 10. Expose 模块：带上下文的文件暴露

- **目标**: 弥补 OneBot v11 等消息平台对大文件/多文件的支持不足。
- **流式下载与零拷贝**: 基于 `axum` 的 `ReaderStream` 实现从磁盘到浏览器的零拷贝直传。
- **任务级缓存与状态**: 支持任务处理状态显示，文件链接默认设置 **24 小时** 过期时间，并修复了任务 URL 上的文件名显示问题。

------

## 🤖 LLM 驱动的工具调用 (LLM Tool Calling)

本项目内置了 LLM 工具链，允许模型通过自然语言指令直接调用复杂的厦大服务 API，以实现智能化操作。这些工具的描述和调用模式通过自定义宏自动生成。

| **工具名称** | **功能描述** | **调用场景** |
|---|---|---|
| `ChooseCourse` | 智能查询/筛选/匹配教务系统中的课程信息。 | “帮我查一下大三上学期的微积分课表。” |
| `ChooseFiles` | 基于用户会话和课程信息，智能定位学习通文件。 | “帮我把高数最近的作业资料下载一下。” |

------

## 💬 指令概览 (Commands)

| **指令** | **逻辑流** | **优化亮点** |
|---|---|---|
| **`/login`** | 身份认证 -> 持久化 | 自动维护教务会话，多端登录不冲突。**新增 LNT 失败回退 JW 机制**，保证登录会话获取的健壮性。登录流程使用 `unsafe` 字节切片进行性能优化。 |
| **`/download`** | 触发 Expose -> 返回链接 | 支持文件分块下载，链接 24h 有效 |
| **`/logout`** | 缓存注销 -> 状态回滚 | $O(1)$ 时间复杂度快速清理热数据 |
| **`/help`** | 自动聚合所有指令帮助信息 | **编译时生成，无需手动维护**。 |
| **`/echo`** | 消息回传 | 继承 `is_echo` 标记，用于端到端延迟测试和指令流判断。**移除了不必要的并发结构 (`DashSet`)，提高了性能**。 |

------

## 📁 项目结构 (Project Structure)

Plaintext

```
├── helper/         # 过程宏定义：实现元编程与 API 自动化封装（如 `box_new!`、`#[handler]`）
├── src/abi/        # 自研 ABI 层：包含路由、消息体解析、网络适配，以及重构后的 OneBot v11 API 声明
├── src/api/        # 核心业务接口：存储(Storage)、教务服务(XMU Service)、LLM（含 `VectorSearchEngine`）
├── src/logic/      # 业务逻辑实现：登录流程、下载处理、客户端辅助
├── src/web/        # Web 服务：Expose 文件暴露系统，弥补文件传输不足
└── benches/        # 性能基准测试：压榨每一纳秒的运行效率（已修复内存安全问题，结果更可靠）
```

------

## 🤝 参与贡献 (Contributing)

我们非常欢迎来自厦大或其他高校的开发者提交 PR！

- **优化 API 定义**: 如果你发现了教务系统（Jw）或畅课系统（Lnt）的新接口，欢迎补充宏定义。
- **改进 Web 视图**: 期待你对 `Expose` 模块 HTML 界面的 UI/UX 优化。
- **性能提升**: 欢迎针对 `benches/` 中的指标提交更优的算法实现。

**提交规范**:

1. 代码必须通过 `cargo fmt` 格式化。
2. 高性能模块的修改请附带 `cargo bench` 结果对比。

# XMUAssistantBot

**XMUAssistantBot** 是一款专为 **厦门大学转专业交流群** 定制的高性能自动化管理机器人。它基于 Rust 异步生态，通过自研消息路由与分层存储架构，在处理 2000 人规模高并发群聊场景下，实现了极致的 I/O 效率与低内存分配。

------

## ⚡ 性能基准 (Performance Benchmark)

基于项目内 `benches/` 模块的实测数据（环境：Linux x64, Release Mode）：

### 1. 消息路由与分发 (ABI Efficiency)

- **轻量化 Context 克隆**: `41.39 ns` — 24 字节极致精简结构，支持瞬时拉起数千个异步 Handler。
- **Context 重负载克隆 (带8条消息)**: `1.99 µs` — 即使在消息处理中后期，克隆开销依然极低。
- **并发 Handler 分发 (x10)**: `20.10 µs` — 模拟 10 个 Handler 同时并行运行的系统级开销。

### 2. 极致的正则与匹配优化

- **自研快速匹配**: 相比标准正则表达式，项目实现的快速匹配逻辑达到了 **67x ~ 110x** 的加速。
  - **传统正则耗时**: `3.51 ms`
  - **快速匹配耗时**: `31.7 µs`

### 3. 存储与序列化性能

- **并发存储吞吐**: `51.58 µs` (100路并发读写) — 完美承载高频会话校验。
- **序列化流水线 (零分配)**: `1.68 µs` — 在 **MiMalloc** 支持下，利用 `serde_json::to_writer` 配合预分配缓冲区，实现 API 请求/响应全流程的“零分配”数据流转。

------

## 🛠️ 深度技术优化 (Technical Deep Dive)

### 1. 极致的内存分配策略

- **MiMalloc 全局分配器**: 放弃系统默认分配器，采用 `MiMalloc` 优化瞬时大量 JSON 对象的分配，极大降低内存碎片率和全局锁竞争。
- **栈空间优先与健壮序列化**:
  - 大量使用 `smol_str` 存储短字符串，通过 Inline 优化避免堆分配。
  - **`define_default_type!` 宏**: 确保 API 响应中的可选字段在缺失或为 `null` 时，能健壮地使用默认值。
  - **存储重构**: `Cold` 和 `Temp` 文件模块已特化为 **一次写入、不可修改** 场景，移除了复杂和低效的后台发送机制，并添加了只读权限和预读缓存。

### 2. 异步 I/O 与分层存储架构

项目实现了 **Hot-Cold-File** 语义化分层存储系统：

- **Hot 层 (DashMap)**: 存储当前活跃的会话（`LoginData`），读写复杂度 $O(1)$。
- **Cold 层 (Redb)**: 采用 Copy-on-Write (CoW) 机制的嵌入式数据库，通过异步 Task 批量提交事务，完全剥离主循环 I/O。
- **RAII 临时文件管理**: 自研 `TempFile` 系统，利用 `Drop` 钩子自动触发异步清理，确保存储空间整洁。
- **ABI & WebSocket 健壮性**:  Handler 异常屏障在显示错误时会显示出错函数，在 WebSocket 生命周期结束时会自动断连。

### 3. 基于过程宏的元编程 (Helper Macros)

项目高度依赖自研过程宏来自动化重复代码、确保运行时性能和安全。

- **`#[handler]` / `register_handlers!`**:
    - **指令与消息类型隔离**: 新增 `echo_cmd` 标记，用于区分**指令回复**和**聊天消息流**。宏自动调用 `Context::set_echo()` 设置上下文标记，彻底重构了聊天转发和指令回答的逻辑，不再依赖内部生成巨大的代码字符串。
    - **统一异常屏障**: 自动包装 Handler 逻辑，捕获并异步处理所有 `anyhow::Result` 错误。
    - **零成本 Context 转换**: 确保了高性能消息路由。
- **API 框架与客户端抽象**: 针对 OneBot v11 接口进行了彻底的框架重构。使用 `#[api]` 宏配合分离的 `Params` 结构体（`src/abi/message/api/params/`），实现 API 客户端的声明式定义和自动化封装，彻底解耦了不同 API 的实现。
- **新增特殊头衔 API**: 实现了 `set_group_special_title` 接口的封装，支持在群聊中设置特殊头衔。
- **核心 Client 抽象**: 核心 API Client 逻辑（如获取 `SessionClient`）已被重构，从宏中剥离出可复用的 `castgc` 和 `session` 模块，大幅减少了重复代码。`logic/helper` 模块的引入，也为一键获取 `SessionClient` 提供了便利。
- **`#[jw_api]` (教务系统)**: 智能适配教务系统非标准的 JSON 嵌套结构。
- **`#[lnt_get_api]` / `#[session_client_helper]` (畅课系统)**: 实现了包括 `activities`、`file_url`、`my_courses`、`profile` 修正等在内的多项 LNT API 封装，利用 URL 模板和客户端辅助宏提升开发效率。
- **`#[derive(LlmPrompt)]`**:
    - **LLM 工具描述生成**: 自动从 Rust 结构体和自定义类型（`tool/type` 下的 `LlmVec`, `LlmOption` 等）中提取信息，生成 LLM 函数调用所需的精确 Schema。该自定义类型系统是为了解决模型返回格式不精确的问题，**实现了实测高准确率的工具化调用**。

### 4. Expose 模块：带上下文的文件暴露

- **目标**: 弥补 OneBot v11 等消息平台对大文件/多文件的支持不足。
- **分块下载支持**: 核心网络模块 (`SessionClient`) 已支持自定义 Header 插入，以适配文件分段下载功能。
- **流式下载与零拷贝**: 基于 `axum` 的 `ReaderStream` 实现从磁盘到浏览器的零拷贝直传。
- **任务级缓存与状态**: 支持任务处理状态显示，文件链接默认设置 **24 小时** 过期时间，并修复了任务 URL 上的文件名显示问题。

------

## 🤖 LLM 驱动的工具调用 (LLM Tool Calling)

本项目内置了 LLM 工具链，允许模型通过自然语言指令直接调用复杂的厦大服务 API，以实现智能化操作。这些工具的描述和调用模式通过自定义宏自动生成。

| **工具名称**      | **功能描述**                                 | **调用场景**                                     |
| ----------------- | -------------------------------------------- | ------------------------------------------------ |
| `ChooseCourse`    | 智能查询/筛选/匹配教务系统中的课程信息。     | “帮我查一下大三上学期的微积分课表。”           |
| `ChooseFiles`     | 基于用户会话和课程信息，智能定位学习通文件。 | “帮我把高数最近的作业资料下载一下。”           |

------

## 💬 指令概览 (Commands)

| **指令**        | **逻辑流**              | **优化亮点**                        |
| --------------- | ----------------------- | ----------------------------------- |
| **`/login`**    | 身份认证 -> 持久化      | 自动维护教务会话，多端登录不冲突    |
| **`/download`** | 触发 Expose -> 返回链接 | 支持文件分块下载，链接 24h 有效      |
| **`/logout`**   | 缓存注销 -> 状态回滚    | $O(1)$ 时间复杂度快速清理热数据     |
| **`/echo`**     | 消息回传                | 继承 `is_echo` 标记，用于端到端延迟测试和指令流判断 |

------

## 📁 项目结构 (Project Structure)

Plaintext

```
├── helper/         # 过程宏定义：实现元编程与 API 自动化封装
├── src/abi/        # 自研 ABI 层：包含路由、消息体解析、网络适配，以及重构后的 OneBot v11 API 声明
├── src/api/        # 核心业务接口：存储(Storage)、教务服务(XMU Service)、LLM
├── src/logic/      # 业务逻辑实现：登录流程、下载处理、客户端辅助
├── src/web/        # Web 服务：Expose 文件暴露系统，弥补文件传输不足
└── benches/        # 性能基准测试：压榨每一纳秒的运行效率
```

------

## 🤝 参与贡献 (Contributing)

我们非常欢迎来自厦大或其他高校的开发者提交 PR！

- **优化 API 定义**: 如果你发现了教务系统（Jw）或畅课系统（Lnt）的新接口，欢迎补充宏定义。
- **改进 Web 视图**: 期待你对 `Expose` 模块 HTML 界面的 UI/UX 优化。
- **性能提升**: 欢迎针对 `benches/` 中的指标提交更优的算法实现。

**提交规范**:

1. 代码必须通过 `cargo fmt` 格式化。
2. 高性能模块的修改请附带 `cargo bench` 结果对比。